"""
TradingAgents FastAPI Service
æä¾›HTTP APIå’ŒWebSocketæ¥å£,åŒ…è£…TradingAgentsæ ¸å¿ƒåŠŸèƒ½
"""
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import asyncio
import json
import os
import uuid
from datetime import datetime
from enum import Enum

# å¯¼å…¥TradingAgentsæ ¸å¿ƒç»„ä»¶
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), "../.."))

from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG
from dotenv import load_dotenv

load_dotenv()

# ==================== æ•°æ®æ¨¡å‹å®šä¹‰ ====================

class AnalystType(str, Enum):
    """åˆ†æå¸ˆç±»å‹"""
    MARKET = "market"
    SOCIAL = "social"
    NEWS = "news"
    FUNDAMENTALS = "fundamentals"

class TaskStatus(str, Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"

class AnalysisRequest(BaseModel):
    """åˆ†æè¯·æ±‚æ¨¡å‹"""
    ticker: str = Field(..., description="è‚¡ç¥¨ä»£ç ", example="NVDA")
    analysis_date: str = Field(..., description="åˆ†ææ—¥æœŸ YYYY-MM-DD", example="2024-05-10")
    selected_analysts: List[AnalystType] = Field(
        default=[AnalystType.MARKET, AnalystType.SOCIAL, AnalystType.NEWS, AnalystType.FUNDAMENTALS],
        description="é€‰æ‹©çš„åˆ†æå¸ˆ"
    )
    research_depth: int = Field(default=1, ge=1, le=5, description="ç ”ç©¶æ·±åº¦(è¾©è®ºè½®æ•°)")
    llm_provider: str = Field(default="openai", description="LLMæä¾›å•†")
    deep_think_llm: str = Field(default="gpt-4o-mini", description="æ·±åº¦æ€è€ƒæ¨¡å‹")
    quick_think_llm: str = Field(default="gpt-4o-mini", description="å¿«é€Ÿæ€è€ƒæ¨¡å‹")
    backend_url: str = Field(default=os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1"), description="LLM APIåœ°å€")
    openai_api_key: Optional[str] = Field(default=None, description="OpenAI APIå¯†é’¥(å¯é€‰,ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡)")
    alpha_vantage_api_key: Optional[str] = Field(default=None, description="Alpha Vantage APIå¯†é’¥(å¯é€‰)")

class AnalysisResponse(BaseModel):
    """åˆ†æå“åº”æ¨¡å‹"""
    task_id: str
    status: TaskStatus
    message: str
    created_at: str

class TaskDetailResponse(BaseModel):
    """ä»»åŠ¡è¯¦æƒ…å“åº”"""
    task_id: str
    status: TaskStatus
    ticker: str
    analysis_date: str
    selected_analysts: List[str]
    research_depth: int
    final_decision: Optional[str] = None
    created_at: str
    completed_at: Optional[str] = None
    error_message: Optional[str] = None

class ProgressMessage(BaseModel):
    """è¿›åº¦æ¶ˆæ¯æ¨¡å‹"""
    type: str  # status, message, tool_call, report
    timestamp: str
    data: Dict[str, Any]

# ==================== WebSocketè¿æ¥ç®¡ç†å™¨ ====================

class ConnectionManager:
    """ç®¡ç†WebSocketè¿æ¥"""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.task_history: Dict[str, List[Dict]] = {}  # å­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„æ¶ˆæ¯å†å²

    async def connect(self, task_id: str, websocket: WebSocket):
        """å»ºç«‹è¿æ¥"""
        await websocket.accept()
        self.active_connections[task_id] = websocket
        print(f"âœ… WebSocketè¿æ¥å·²å»ºç«‹: {task_id}")

        # å‘é€å†å²æ¶ˆæ¯(å¦‚æœæœ‰)
        if task_id in self.task_history:
            for msg in self.task_history[task_id]:
                try:
                    await websocket.send_json(msg)
                except:
                    pass

    def disconnect(self, task_id: str):
        """æ–­å¼€è¿æ¥"""
        if task_id in self.active_connections:
            del self.active_connections[task_id]
            print(f"âŒ WebSocketè¿æ¥å·²æ–­å¼€: {task_id}")

    async def send_progress(self, task_id: str, message_type: str, data: Dict[str, Any]):
        """å‘é€è¿›åº¦æ¶ˆæ¯"""
        message = {
            "type": message_type,
            "timestamp": datetime.now().isoformat(),
            "data": data
        }

        # ä¿å­˜åˆ°å†å²
        if task_id not in self.task_history:
            self.task_history[task_id] = []
        self.task_history[task_id].append(message)

        # å‘é€ç»™è¿æ¥çš„å®¢æˆ·ç«¯
        if task_id in self.active_connections:
            try:
                await self.active_connections[task_id].send_json(message)
                print(f"ğŸ“¤ å‘é€æ¶ˆæ¯ [{message_type}]: {task_id}")
            except Exception as e:
                print(f"âŒ å‘é€æ¶ˆæ¯å¤±è´¥ {task_id}: {e}")

# ==================== å…¨å±€å˜é‡ ====================

app = FastAPI(
    title="TradingAgents API",
    description="Multi-Agents LLM Financial Trading Framework API",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒéœ€è¦é™åˆ¶
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# WebSocketç®¡ç†å™¨
manager = ConnectionManager()

# ä»»åŠ¡å­˜å‚¨(ç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨æ•°æ®åº“)
tasks_db: Dict[str, Dict] = {}

# çº¿ç¨‹æ± æ‰§è¡Œå™¨ (ç”¨äºçœŸæ­£çš„åå°å¼‚æ­¥æ‰§è¡Œ)
from concurrent.futures import ThreadPoolExecutor
executor = ThreadPoolExecutor(max_workers=4)  # æ”¯æŒ4ä¸ªå¹¶å‘ä»»åŠ¡

# ==================== è¾…åŠ©å‡½æ•° ====================

def send_progress_sync(task_id: str, message_type: str, data: Dict[str, Any]):
    """åŒæ­¥å‘é€è¿›åº¦æ¶ˆæ¯ (çº¿ç¨‹å®‰å…¨)"""
    message = {
        "type": message_type,
        "timestamp": datetime.now().isoformat(),
        "data": data
    }

    # ä¿å­˜åˆ°å†å²
    if task_id not in manager.task_history:
        manager.task_history[task_id] = []
    manager.task_history[task_id].append(message)

    # å¦‚æœæœ‰WebSocketè¿æ¥,å°è¯•å‘é€ (ä½¿ç”¨asyncio)
    if task_id in manager.active_connections:
        try:
            # åœ¨äº‹ä»¶å¾ªç¯ä¸­è°ƒåº¦å‘é€
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(
                manager.active_connections[task_id].send_json(message)
            )
            print(f"ğŸ“¤ å‘é€æ¶ˆæ¯ [{message_type}]: {task_id}")
        except Exception as e:
            print(f"âš ï¸ å‘é€WebSocketæ¶ˆæ¯å¤±è´¥ {task_id}: {e}")

# ==================== åå°ä»»åŠ¡å¤„ç† ====================

def run_analysis_task_sync(task_id: str, request: AnalysisRequest):
    """åŒæ­¥è¿è¡Œåˆ†æä»»åŠ¡ (åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œ)"""
    ta = None  # åˆå§‹åŒ–ä¸ºNone,ç”¨äºfinallyå—æ¸…ç†

    # ç»Ÿè®¡æŒ‡æ ‡
    tool_call_count = 0
    llm_call_count = 0
    report_count = 0

    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        tasks_db[task_id]["status"] = TaskStatus.RUNNING

        send_progress_sync(task_id, "status", {
            "status": "running",
            "message": f"å¼€å§‹åˆ†æ {request.ticker} on {request.analysis_date}"
        })

        # é…ç½®APIå¯†é’¥(å¦‚æœæä¾›)
        original_openai_key = os.environ.get("OPENAI_API_KEY")
        original_av_key = os.environ.get("ALPHA_VANTAGE_API_KEY")

        if request.openai_api_key:
            os.environ["OPENAI_API_KEY"] = request.openai_api_key
        if request.alpha_vantage_api_key:
            os.environ["ALPHA_VANTAGE_API_KEY"] = request.alpha_vantage_api_key

        # åˆ›å»ºé…ç½®
        config = DEFAULT_CONFIG.copy()
        config["deep_think_llm"] = request.deep_think_llm
        config["quick_think_llm"] = request.quick_think_llm
        config["max_debate_rounds"] = request.research_depth
        config["max_risk_discuss_rounds"] = request.research_depth
        config["llm_provider"] = request.llm_provider
        config["backend_url"] = request.backend_url

        # ä¸ºæ¯ä¸ªä»»åŠ¡è®¾ç½®å”¯ä¸€çš„å†…å­˜å‰ç¼€,é¿å…å¹¶å‘ä»»åŠ¡é—´çš„å†…å­˜æ±¡æŸ“
        config["memory_prefix"] = f"task_{task_id[:8]}_"

        print(f"ğŸš€ åˆå§‹åŒ– TradingAgentsGraph, åˆ†æå¸ˆ: {[a.value for a in request.selected_analysts]}")
        print(f"ğŸ“ å†…å­˜å‰ç¼€: {config['memory_prefix']}")

        # åˆå§‹åŒ–TradingAgents
        ta = TradingAgentsGraph(
            selected_analysts=[analyst.value for analyst in request.selected_analysts],
            debug=True,
            config=config
        )

        send_progress_sync(task_id, "status", {
            "status": "running",
            "message": "TradingAgents åˆå§‹åŒ–å®Œæˆ"
        })

        # åˆ›å»ºåˆå§‹çŠ¶æ€
        init_state = ta.propagator.create_initial_state(
            request.ticker,
            request.analysis_date
        )
        args = ta.propagator.get_graph_args()

        print(f"ğŸ“Š å¼€å§‹æµå¼æ‰§è¡Œåˆ†æ...")

        # æµå¼æ‰§è¡Œåˆ†æ
        chunk_count = 0
        final_chunk = None

        for chunk in ta.graph.stream(init_state, **args):
            chunk_count += 1
            final_chunk = chunk

            # æ£€æµ‹å½“å‰æ´»è·ƒçš„èŠ‚ç‚¹/Agent
            # LangGraphçš„chunkå¯èƒ½åŒ…å«èŠ‚ç‚¹åç§°ä¿¡æ¯
            chunk_keys = list(chunk.keys())
            for key in chunk_keys:
                # å‘é€èŠ‚ç‚¹æ¿€æ´»ä¿¡æ¯
                if key not in ["messages"] and chunk.get(key):
                    # æ˜ å°„èŠ‚ç‚¹ååˆ°Agent
                    agent_mapping = {
                        "market_analyst": "market",
                        "social_analyst": "social",
                        "news_analyst": "news",
                        "fundamentals_analyst": "fundamentals",
                        "bull_researcher": "bull",
                        "bear_researcher": "bear",
                        "research_manager": "research-manager",
                        "trader": "trader",
                        "risky_analyst": "risk-risky",
                        "safe_analyst": "risk-safe",
                        "neutral_analyst": "risk-neutral",
                        "risk_manager": "risk-manager"
                    }

                    if key in agent_mapping:
                        send_progress_sync(task_id, "agent_status", {
                            "agent": agent_mapping[key],
                            "status": "running"
                        })

            # å¤„ç†æ¶ˆæ¯
            if len(chunk.get("messages", [])) > 0:
                last_message = chunk["messages"][-1]
                llm_call_count += 1  # æ¯ä¸ªæ¶ˆæ¯éƒ½æ˜¯ä¸€æ¬¡LLMè°ƒç”¨

                # æå–å†…å®¹
                if hasattr(last_message, "content"):
                    content = last_message.content
                    if isinstance(content, list):
                        # å¤„ç†Anthropicæ ¼å¼
                        text_parts = []
                        for item in content:
                            if isinstance(item, dict) and item.get('type') == 'text':
                                text_parts.append(item.get('text', ''))
                        content = ' '.join(text_parts)

                    send_progress_sync(task_id, "message", {
                        "content": str(content),  # å‘é€å®Œæ•´å†…å®¹
                        "stats": {
                            "tool_calls": tool_call_count,
                            "llm_calls": llm_call_count,
                            "reports": report_count
                        }
                    })

                # å¤„ç†å·¥å…·è°ƒç”¨
                if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                    for tool_call in last_message.tool_calls:
                        tool_call_count += 1  # ç»Ÿè®¡å·¥å…·è°ƒç”¨æ¬¡æ•°

                        tool_name = tool_call.get("name") if isinstance(tool_call, dict) else getattr(tool_call, "name", "unknown")
                        tool_args = tool_call.get("args") if isinstance(tool_call, dict) else getattr(tool_call, "args", {})

                        send_progress_sync(task_id, "tool_call", {
                            "tool_name": tool_name,
                            "args": tool_args,
                            "stats": {
                                "tool_calls": tool_call_count,
                                "llm_calls": llm_call_count,
                                "reports": report_count
                            }
                        })

            # å¤„ç†æŠ¥å‘Š
            report_types = [
                "market_report", "sentiment_report", "news_report",
                "fundamentals_report", "investment_plan",
                "trader_investment_plan", "final_trade_decision"
            ]

            for report_type in report_types:
                if report_type in chunk and chunk[report_type]:
                    report_count += 1  # ç»Ÿè®¡æŠ¥å‘Šç”Ÿæˆæ¬¡æ•°

                    send_progress_sync(task_id, "report", {
                        "report_type": report_type,
                        "content": chunk[report_type],
                        "stats": {
                            "tool_calls": tool_call_count,
                            "llm_calls": llm_call_count,
                            "reports": report_count
                        }
                    })

                    # ä¿å­˜åˆ°ä»»åŠ¡æ•°æ®
                    if "reports" not in tasks_db[task_id]:
                        tasks_db[task_id]["reports"] = {}
                    tasks_db[task_id]["reports"][report_type] = chunk[report_type]

        print(f"âœ… åˆ†æå®Œæˆ,å…±å¤„ç† {chunk_count} ä¸ªchunk")

        # è·å–æœ€ç»ˆå†³ç­–
        if final_chunk and "final_trade_decision" in final_chunk:
            decision = ta.process_signal(final_chunk["final_trade_decision"])
            tasks_db[task_id]["final_decision"] = decision
            tasks_db[task_id]["final_state"] = final_chunk
        else:
            decision = "UNKNOWN"

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
        tasks_db[task_id]["status"] = TaskStatus.COMPLETED
        tasks_db[task_id]["completed_at"] = datetime.now().isoformat()

        send_progress_sync(task_id, "status", {
            "status": "completed",
            "decision": decision,
            "message": f"åˆ†æå®Œæˆ! å†³ç­–: {decision}"
        })

        # æ¢å¤åŸå§‹APIå¯†é’¥
        if original_openai_key:
            os.environ["OPENAI_API_KEY"] = original_openai_key
        if original_av_key:
            os.environ["ALPHA_VANTAGE_API_KEY"] = original_av_key

    except Exception as e:
        print(f"âŒ åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

        tasks_db[task_id]["status"] = TaskStatus.FAILED
        tasks_db[task_id]["error_message"] = str(e)
        tasks_db[task_id]["completed_at"] = datetime.now().isoformat()

        send_progress_sync(task_id, "status", {
            "status": "failed",
            "error": str(e)
        })
    finally:
        # æ¸…ç†å†…å­˜é›†åˆ,é‡Šæ”¾èµ„æº,é¿å…å†…å­˜æ³„æ¼
        if ta is not None:
            try:
                ta.cleanup_memory()
                print(f"ğŸ§¹ ä»»åŠ¡ {task_id[:8]} å†…å­˜å·²æ¸…ç†")
            except Exception as cleanup_error:
                print(f"âš ï¸ æ¸…ç†ä»»åŠ¡ {task_id[:8]} å†…å­˜æ—¶å‡ºé”™: {cleanup_error}")

# ==================== APIç«¯ç‚¹ ====================

@app.get("/", tags=["å¥åº·æ£€æŸ¥"])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "TradingAgents API",
        "status": "running",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/api/v1/health", tags=["å¥åº·æ£€æŸ¥"])
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "TradingAgents API",
        "timestamp": datetime.now().isoformat(),
        "active_tasks": len(tasks_db),
        "active_websockets": len(manager.active_connections)
    }

@app.post("/api/v1/analysis/start", response_model=AnalysisResponse, tags=["åˆ†æ"])
async def start_analysis(
    request: AnalysisRequest
):
    """
    å¯åŠ¨æ–°çš„åˆ†æä»»åŠ¡

    - **ticker**: è‚¡ç¥¨ä»£ç ,å¦‚ NVDA, AAPL, TSLA
    - **analysis_date**: åˆ†ææ—¥æœŸ,æ ¼å¼ YYYY-MM-DD
    - **selected_analysts**: é€‰æ‹©çš„åˆ†æå¸ˆåˆ—è¡¨
    - **research_depth**: ç ”ç©¶æ·±åº¦(è¾©è®ºè½®æ•°), 1-5
    """
    # ç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())

    # åˆ›å»ºä»»åŠ¡è®°å½•
    tasks_db[task_id] = {
        "task_id": task_id,
        "status": TaskStatus.PENDING,
        "ticker": request.ticker,
        "analysis_date": request.analysis_date,
        "selected_analysts": [a.value for a in request.selected_analysts],
        "research_depth": request.research_depth,
        "created_at": datetime.now().isoformat(),
        "reports": {},
        "final_decision": None,
        "completed_at": None,
        "error_message": None
    }

    # ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œä»»åŠ¡ (çœŸæ­£çš„å¹¶å‘)
    loop = asyncio.get_event_loop()
    loop.run_in_executor(executor, run_analysis_task_sync, task_id, request)

    print(f"âœ¨ åˆ›å»ºåˆ†æä»»åŠ¡: {task_id} - {request.ticker} on {request.analysis_date}")

    return AnalysisResponse(
        task_id=task_id,
        status=TaskStatus.PENDING,
        message=f"åˆ†æä»»åŠ¡å·²åˆ›å»º: {request.ticker}",
        created_at=tasks_db[task_id]["created_at"]
    )

@app.get("/api/v1/analysis/{task_id}", response_model=TaskDetailResponse, tags=["åˆ†æ"])
async def get_task_detail(task_id: str):
    """
    è·å–ä»»åŠ¡è¯¦æƒ…
    """
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task = tasks_db[task_id]

    return TaskDetailResponse(
        task_id=task["task_id"],
        status=task["status"],
        ticker=task["ticker"],
        analysis_date=task["analysis_date"],
        selected_analysts=task["selected_analysts"],
        research_depth=task["research_depth"],
        final_decision=task.get("final_decision"),
        created_at=task["created_at"],
        completed_at=task.get("completed_at"),
        error_message=task.get("error_message")
    )

@app.get("/api/v1/analysis/{task_id}/reports", tags=["åˆ†æ"])
async def get_task_reports(task_id: str):
    """
    è·å–ä»»åŠ¡çš„æ‰€æœ‰æŠ¥å‘Š
    """
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    return {
        "task_id": task_id,
        "status": tasks_db[task_id]["status"],
        "reports": tasks_db[task_id].get("reports", {})
    }

@app.get("/api/v1/tasks", tags=["åˆ†æ"])
async def list_tasks(status: Optional[TaskStatus] = None, limit: int = 20):
    """
    åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
    """
    tasks = list(tasks_db.values())

    if status:
        tasks = [t for t in tasks if t["status"] == status]

    # æŒ‰åˆ›å»ºæ—¶é—´å€’åº
    tasks.sort(key=lambda x: x["created_at"], reverse=True)

    return {
        "total": len(tasks),
        "tasks": tasks[:limit]
    }

@app.websocket("/ws/analysis/{task_id}")
async def websocket_endpoint(websocket: WebSocket, task_id: str):
    """
    WebSocketç«¯ç‚¹,ç”¨äºæ¥æ”¶å®æ—¶åˆ†æè¿›åº¦

    è¿æ¥åä¼šæ”¶åˆ°ä»¥ä¸‹ç±»å‹çš„æ¶ˆæ¯:
    - status: çŠ¶æ€æ›´æ–°
    - message: LLMæ¨ç†æ¶ˆæ¯
    - tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
    - report: æŠ¥å‘Šç”Ÿæˆ
    """
    await manager.connect(task_id, websocket)
    try:
        while True:
            # ä¿æŒè¿æ¥,æ¥æ”¶å®¢æˆ·ç«¯ping
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    except WebSocketDisconnect:
        manager.disconnect(task_id)
    except Exception as e:
        print(f"WebSocketå¼‚å¸¸: {e}")
        manager.disconnect(task_id)

# ==================== å¯åŠ¨é…ç½® ====================

if __name__ == "__main__":
    import uvicorn

    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         TradingAgents FastAPI Service                     â•‘
    â•‘                                                           â•‘
    â•‘  API æ–‡æ¡£: http://localhost:8000/docs                     â•‘
    â•‘  å¥åº·æ£€æŸ¥: http://localhost:8000/api/v1/health           â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
